{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNw48Bvs/Dnp2suSPbToePN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanlalaIbrahim/AI/blob/main/Q_learning_%26_SARSA_Taxi_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "G4w7GEWUWnTz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import gym"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eps_greedy(Q, s, eps=0.1):\n",
        "  if np.random.uniform(0,1)<eps:\n",
        "    return np.random.randint(Q.shape[1])\n",
        "  else:\n",
        "    return greedy(Q, s)"
      ],
      "metadata": {
        "id": "q2zpy_WuWuzv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Greedy** **Policy**\n",
        "\n",
        "> *Returning to Maximum Action State Value*\n",
        "\n"
      ],
      "metadata": {
        "id": "2Idx_3AxXweO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy(Q, s):\n",
        "    return np.argmax(Q[s])"
      ],
      "metadata": {
        "id": "IEsGhkfiYKgZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Policy** **Testing**"
      ],
      "metadata": {
        "id": "7EOHQySiYSJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def run_episodes(env, Q, num_episodes=100, to_print=False):\n",
        "  tot_rew = []\n",
        "  state = env.reset()\n",
        "\n",
        "  for _ in range(num_episodes):\n",
        "    done = False\n",
        "    game_rew = 0\n",
        "\n",
        "    while not done:\n",
        "      next_state, rew, done, _ = env.step(greedy(Q, state))\n",
        "\n",
        "      state = next_state\n",
        "      game_rew += rew\n",
        "      if done:\n",
        "        state = env.reset()\n",
        "        tot_rew.append(game_rew)\n",
        "\n",
        "  if to_print:\n",
        "    print('Mean Score: %.3f of %i games!'%(np.mean(tot_rew), num_episodes))\n",
        "\n",
        "  return np.mean(tot_rew)"
      ],
      "metadata": {
        "id": "pEijfIYMY1qD"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**SARSA**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*  initialize Q Matrix\n",
        "*   Decay tge epsion untill it reaches the threshold\n",
        "*   Choose next Action\n",
        "*   SARSA Update\n",
        "*   Testing the Policy\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2rAbjumCb3_E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#      **Bellman** **Equation**\n",
        "      \n",
        "      Q[state][action] = Q[state][action] + lr*(rew + gamma*Q[next_state][next_action] - Q[state][action])"
      ],
      "metadata": {
        "id": "ovk7uTl5OpZZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def SARSA(env, lr=0.01, num_episodes=10000, eps=0.3, gamma=0.95, eps_decay=0.00005):\n",
        "  nA = env.action_space.n\n",
        "  nS = env.observation_space.n\n",
        "\n",
        "  Q = np.zeros((nS, nA))\n",
        "  games_rewards = []\n",
        "  test_rewards = []\n",
        "\n",
        "  for ep in range(num_episodes):\n",
        "    state =  env.reset()\n",
        "    done = False\n",
        "    tot_rew = 0\n",
        "\n",
        "    if eps > 0.01:\n",
        "      eps -= eps_decay\n",
        "\n",
        "\n",
        "    action = eps_greedy(Q, state, eps)\n",
        "\n",
        "    while not done:\n",
        "      next_state, rew, done, _ = env.step(action)\n",
        "\n",
        "      next_action =  eps_greedy(Q, next_state, eps)\n",
        "\n",
        "      Q[state][action] = Q[state][action] + lr*(rew + gamma*Q[next_state][next_action] - Q[state][action])\n",
        "\n",
        "      state = next_state\n",
        "      action = next_action\n",
        "      tot_rew += rew\n",
        "      if done:\n",
        "        games_rewards.append(tot_rew)\n",
        "\n",
        "    if (ep % 300) == 0:\n",
        "      test_rew = run_episodes(env, Q, 1000)\n",
        "      print(\"Episode:{:5d} Eps:{:2.4f} Rew:{:2.4f}\".format(ep, eps, test_rew))\n",
        "      test_rewards.append(test_rew)\n",
        "\n",
        "  return Q"
      ],
      "metadata": {
        "id": "wLCR0FLWfW51"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **SARSA - Taxi v3 Data**"
      ],
      "metadata": {
        "id": "YQISt7mMMfUd"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t17G3Q8tVk9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  env = gym.make('Taxi-v3')\n",
        "  print('SARSA')\n",
        "  Q_sarsa = SARSA(env, lr=0.01, num_episodes=10000, eps=0.3, gamma=0.95, eps_decay=0.00005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YvvkTdiLMs21",
        "outputId": "2b981553-8bb0-4efd-d380-5e89077d95b8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SARSA\n",
            "Episode:    0 Eps:0.2999 Rew:-230.4200\n",
            "Episode:  300 Eps:0.2850 Rew:-216.0740\n",
            "Episode:  600 Eps:0.2700 Rew:-200.0000\n",
            "Episode:  900 Eps:0.2550 Rew:-200.0000\n",
            "Episode: 1200 Eps:0.2400 Rew:-198.9300\n",
            "Episode: 1500 Eps:0.2250 Rew:-200.0000\n",
            "Episode: 1800 Eps:0.2100 Rew:-200.0000\n",
            "Episode: 2100 Eps:0.1950 Rew:-200.0000\n",
            "Episode: 2400 Eps:0.1800 Rew:-199.5720\n",
            "Episode: 2700 Eps:0.1650 Rew:-198.7100\n",
            "Episode: 3000 Eps:0.1500 Rew:-199.1400\n",
            "Episode: 3300 Eps:0.1350 Rew:-192.7920\n",
            "Episode: 3600 Eps:0.1200 Rew:-194.6680\n",
            "Episode: 3900 Eps:0.1050 Rew:-191.6850\n",
            "Episode: 4200 Eps:0.0900 Rew:-183.0030\n",
            "Episode: 4500 Eps:0.0750 Rew:-185.7270\n",
            "Episode: 4800 Eps:0.0600 Rew:-187.4600\n",
            "Episode: 5100 Eps:0.0450 Rew:-182.5400\n",
            "Episode: 5400 Eps:0.0300 Rew:-170.5670\n",
            "Episode: 5700 Eps:0.0150 Rew:-177.9150\n",
            "Episode: 6000 Eps:0.0100 Rew:-175.8710\n",
            "Episode: 6300 Eps:0.0100 Rew:-157.3940\n",
            "Episode: 6600 Eps:0.0100 Rew:-164.6840\n",
            "Episode: 6900 Eps:0.0100 Rew:-160.2670\n",
            "Episode: 7200 Eps:0.0100 Rew:-196.4790\n",
            "Episode: 7500 Eps:0.0100 Rew:-153.9190\n",
            "Episode: 7800 Eps:0.0100 Rew:-152.7920\n",
            "Episode: 8100 Eps:0.0100 Rew:-174.4010\n",
            "Episode: 8400 Eps:0.0100 Rew:-165.0150\n",
            "Episode: 8700 Eps:0.0100 Rew:-123.0020\n",
            "Episode: 9000 Eps:0.0100 Rew:-121.3680\n",
            "Episode: 9300 Eps:0.0100 Rew:-152.2240\n",
            "Episode: 9600 Eps:0.0100 Rew:-174.8450\n",
            "Episode: 9900 Eps:0.0100 Rew:-102.6600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GeSPLOSRKab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q-Learning**\n",
        "\n",
        "* initilalizing Q matrix\n",
        "* Decay the epsilon untill it reaches the threshold\n",
        "* Select Action Following Epsilon-Greedy policy\n",
        "* Q-Learning updates State-Action Value\n",
        "* Testing the Policy"
      ],
      "metadata": {
        "id": "K0ky3R6jVnly"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Q_Learning(env, lr=0.01, num_episodes=10000, eps=0.3, gamma=0.95, eps_decay=0.00005):\n",
        "  nA = env.action_space.n\n",
        "  nS = env.observation_space.n\n",
        "\n",
        "  Q = np.zeros((nS, nA))\n",
        "  games_rewards = []\n",
        "  test_rewards = []\n",
        "\n",
        "  for ep in range(num_episodes):\n",
        "    state =  env.reset()\n",
        "    done = False\n",
        "    tot_rew = 0\n",
        "\n",
        "    if eps > 0.01:\n",
        "      eps -= eps_decay\n",
        "\n",
        "    while not done:\n",
        "      action = eps_greedy(Q, state, eps)\n",
        "\n",
        "      next_state, rew, done, _ = env.step(action)\n",
        "\n",
        "\n",
        "      Q[state][action] = Q[state][action] + lr*(rew + gamma*np.max([next_state]) - Q[state][action])\n",
        "\n",
        "      state = next_state\n",
        "      tot_rew += rew\n",
        "      if done:\n",
        "        games_rewards.append(tot_rew)\n",
        "\n",
        "    if (ep % 300) == 0:\n",
        "      test_rew = run_episodes(env, Q, 1000)\n",
        "      print(\"Episode:{:5d} Eps:{:2.4f} Rew:{:2.4f}\".format(ep, eps, test_rew))\n",
        "      test_rewards.append(test_rew)\n",
        "\n",
        "  return Q"
      ],
      "metadata": {
        "id": "whbc_mL-ZAxq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RWF5oQ9NZap3"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Q-Learning - Taxi v3 Data**"
      ],
      "metadata": {
        "id": "kkBqc-alaAKs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  env = gym.make('Taxi-v3')\n",
        "  print('Q-Learning')\n",
        "  Q_Learning = Q_Learning(env, lr=0.01, num_episodes=10000, eps=0.3, gamma=0.95, eps_decay=0.00005)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ahRpipfaHSX",
        "outputId": "931d86d2-45e8-4bc1-d845-c1404d02e552"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Q-Learning\n",
            "Episode:    0 Eps:0.2999 Rew:-233.9660\n",
            "Episode:  300 Eps:0.2850 Rew:-524.1350\n",
            "Episode:  600 Eps:0.2700 Rew:-535.0430\n",
            "Episode:  900 Eps:0.2550 Rew:-504.8300\n",
            "Episode: 1200 Eps:0.2400 Rew:-504.5960\n",
            "Episode: 1500 Eps:0.2250 Rew:-477.7130\n",
            "Episode: 1800 Eps:0.2100 Rew:-502.4360\n",
            "Episode: 2100 Eps:0.1950 Rew:-502.7600\n",
            "Episode: 2400 Eps:0.1800 Rew:-461.7290\n",
            "Episode: 2700 Eps:0.1650 Rew:-434.9810\n",
            "Episode: 3000 Eps:0.1500 Rew:-429.4370\n",
            "Episode: 3300 Eps:0.1350 Rew:-484.3730\n",
            "Episode: 3600 Eps:0.1200 Rew:-534.1970\n",
            "Episode: 3900 Eps:0.1050 Rew:-473.7170\n",
            "Episode: 4200 Eps:0.0900 Rew:-398.4680\n",
            "Episode: 4500 Eps:0.0750 Rew:-400.6190\n",
            "Episode: 4800 Eps:0.0600 Rew:-413.1740\n",
            "Episode: 5100 Eps:0.0450 Rew:-434.6660\n",
            "Episode: 5400 Eps:0.0300 Rew:-422.1740\n",
            "Episode: 5700 Eps:0.0150 Rew:-368.2730\n",
            "Episode: 6000 Eps:0.0100 Rew:-398.7920\n",
            "Episode: 6300 Eps:0.0100 Rew:-372.1340\n",
            "Episode: 6600 Eps:0.0100 Rew:-377.4890\n",
            "Episode: 6900 Eps:0.0100 Rew:-380.9810\n",
            "Episode: 7200 Eps:0.0100 Rew:-391.8080\n",
            "Episode: 7500 Eps:0.0100 Rew:-381.1160\n",
            "Episode: 7800 Eps:0.0100 Rew:-359.5520\n",
            "Episode: 8100 Eps:0.0100 Rew:-388.1450\n",
            "Episode: 8400 Eps:0.0100 Rew:-374.2040\n",
            "Episode: 8700 Eps:0.0100 Rew:-356.2760\n",
            "Episode: 9000 Eps:0.0100 Rew:-356.2850\n",
            "Episode: 9300 Eps:0.0100 Rew:-341.9030\n",
            "Episode: 9600 Eps:0.0100 Rew:-354.5480\n",
            "Episode: 9900 Eps:0.0100 Rew:-363.5570\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Sbi7-Ao0aWuO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}